{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww37900\viewh22220\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 1.\
How to create  and T matrices.\
One option is to read each sub matrix once and update all S and T matrices.  This requires a read and write of S and T for each addition but only needs to read each input matrix once.\
Alternatively, we can write S and T once but we read each matrix block for each addition that forms the S and T matrix.\
Currently, we take the latter approach.\
\
2.\
Single temp allocation versus #(rank) matrix allocation.  \
With single temp we write the M matrices after every subproblem multiplication.\
With multiple temps, we only need to read and write the M matrices once, but we require more memory.\
Currently, we use multiple temps.\
\
3.\
For single adds, copy data contiguously or not.\
When copying contiguously, we can absorb the coefficient into the matrix in the copy.\
If we don\'92t copy, then we need the coefficient in the GEMM call (propagation of the coefficients).\
Currently, we copy everything except single adds where the coefficient is one.  The reason for this choice is that it was simple to code.\
\
4.\
Use AXPY or write custom adds?\
AXPY is highly optimized but we can only add one at a time.  This results in many more reads and writes than is necessary.\
With custom adds, we can do the optimal number of reads and writes.\
Currently, we use custom adds because they are much faster in practice.  We can do some hand-tuning of our Adds.}